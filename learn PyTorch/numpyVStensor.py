import torch
import numpy as np

a = np.array([1., 2., 3.])
t = torch.from_numpy(a)
# print(a)
# print(t)
#   [1. 2. 3.]
#   tensor([1., 2., 3.], dtype=torch.float64)

t += 1

# print(a)
# print(t)
#   [2. 3. 4.] ค่าใน numpy เปลี่ยนตาม
#   tensor([2., 3., 4.], dtype=torch.float64)

# --------------------------------------------------------------

t = torch.tensor([1, 2, 3])
b = t.numpy()
# print(b)
#   [1 2 3]

b+=1
# print(t)
# print(b)
#   tensor([2, 3, 4])
#   [2 3 4] ค่าเปลี่ยนตาม

# --------------------------------------------------------------

t = torch.tensor([1, 2, 3])
b = t.numpy()
b+=1
# print(t)
# print(b)
#   tensor([2, 3, 4])
#   [2 3 4]

# --------------------------------------------------------------

t1 = torch.ones(5, 3)
t2 = torch.Tensor(3,5).fill_(7)

# print("t1:", t1)
# print("t2:", t2)
# print("dot product:", torch.matmul(t1, t2))
#   t1: tensor([[1., 1., 1.],
#             [1., 1., 1.],
#             [1., 1., 1.],
#             [1., 1., 1.],
#             [1., 1., 1.]])
#   t2: tensor([[7., 7., 7., 7., 7.],
#             [7., 7., 7., 7., 7.],
#             [7., 7., 7., 7., 7.]])
#   dot product: tensor([[21., 21., 21., 21., 21.],
#             [21., 21., 21., 21., 21.],
#             [21., 21., 21., 21., 21.],
#             [21., 21., 21., 21., 21.],
#             [21., 21., 21., 21., 21.]])

# --------------------------------------------------------------

t = torch.ones(5, 3)
# print(t)
# print(t.mean())
# print(t.sum())
# print(t.std())
# print(t.min())
# print(t.max())
#   tensor([[1., 1., 1.],
#           [1., 1., 1.],
#           [1., 1., 1.],
#           [1., 1., 1.],
#           [1., 1., 1.]])
#   tensor(1.)
#   tensor(15.)
#   tensor(0.)
#   tensor(1.)
#   tensor(1.)

# --------------------------------------------------------------

t = torch.randn(5, 3)
# print(t)
# print(t.view(1, 15))
# print(t.view(3, 5))
# print(t.flatten())
#   tensor([[-0.3365, -1.3688,  0.4941],
#           [ 0.4426,  1.8893,  0.2775],
#           [ 1.4092,  0.8112, -1.3378],
#           [-0.0616, -1.0503, -1.2827],
#           [-1.4078, -1.0260, -0.3316]])
#   tensor([[-0.3365, -1.3688,  0.4941,  0.4426,  1.8893,  0.2775,  1.4092,  0.8112, -1.3378, -0.0616, -1.0503, -1.2827, -1.4078, -1.0260, -0.3316]])
#   tensor([[-0.3365, -1.3688,  0.4941,  0.4426,  1.8893],
#           [ 0.2775,  1.4092,  0.8112, -1.3378, -0.0616],
#           [-1.0503, -1.2827, -1.4078, -1.0260, -0.3316]])
#   tensor([-0.3365, -1.3688,  0.4941,  0.4426,  1.8893,  0.2775,  1.4092,  0.8112, -1.3378, -0.0616, -1.0503, -1.2827, -1.4078, -1.0260, -0.3316])

# --------------------------------------------------------------

device = torch.device("cuda" if torch.cuda.is_available()
                       else "mps" if torch.mps.is_available()
                       else "cpu")
# print("Using device:", device)
t = torch.randn(5, 3).to(device)
# print(t)
#   Using device: cuda
#   tensor([[ 1.4270,  1.3556, -1.3135],
#           [ 0.0460,  1.5378,  1.2594],
#           [-0.4503, -0.5295,  0.6574],
#           [-2.1684,  0.5228,  1.1118],
#           [ 1.3842, -0.1759, -1.3262]], device='cuda:0')

# --------------------------------------------------------------

x = torch.ones(1, 5).to(device)
w = torch.empty(5, 1).fill_(2.0).to(device)

w.requires_grad = True
y = torch.matmul(x, w)

y.backward()
print(y.grad)
print(w.grad)
print(x.grad)
#   None
#   tensor([[1.],
#           [1.],
#           [1.],
#           [1.],
#           [1.]], device='cuda:0')
#   None